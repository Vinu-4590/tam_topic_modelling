{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1\n",
    "\n",
    "Source: \n",
    "1. https://github.com/aws/amazon-sagemaker-examples/blob/master/scientific_details_of_algorithms/ntm_topic_modeling/ntm_wikitext.ipynb\n",
    "2. https://sagemaker-examples.readthedocs.io/en/latest/introduction_to_amazon_algorithms/ntm_synthetic/ntm_synthetic.html#Extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import boto3\n",
    "import dask.dataframe as dd\n",
    "import tempfile\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "# %matplotlib notebook\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 5000)\n",
    "pd.set_option('display.float_format', str)\n",
    "matplotlib.rcParams['figure.figsize'] = (10, 10)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "working_dir = '/home/ec2-user/SageMaker'\n",
    "base_dir = '/home/ec2-user/SageMaker/topic_modelling/'\n",
    "# s3_data_path = 's3://bucket-sushant/bangla-character-recognition/'\n",
    "\n",
    "## For reproducible results\n",
    "seed_value = 18\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "# https://stackoverflow.com/questions/5836335/consistently-create-same-random-numpy-array/5837352#5837352\n",
    "random_state = np.random.RandomState(seed=seed_value)\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "def read_from_s3(file_path):\n",
    "    bucket_name = file_path.split('/')[2]\n",
    "    key = '/'.join(file_path.split('/')[3:])\n",
    "    response = s3.get_object(Bucket=bucket_name, Key=key)\n",
    "    body = response['Body'].read()\n",
    "    return body\n",
    "\n",
    "def read_pickle_from_s3(file_path):\n",
    "    data = pickle.loads(read_from_s3(file_path))\n",
    "    return data\n",
    "\n",
    "# def read_csv_from_s3(file_path):\n",
    "#     data = pd.read_csv(file_path, low_memory=False)\n",
    "#     return data\n",
    "\n",
    "def store_object_to_s3_as_pickle(data, file_path):\n",
    "    bucket_name = file_path.split('/')[2]\n",
    "    key = '/'.join(file_path.split('/')[3:])\n",
    "#     # uses lot of memory\n",
    "#     pickle_obj = pickle.dumps(data)\n",
    "#     return s3.put_object(Key=key, Bucket=bucket_name, Body=pickle_obj)\n",
    "    # using tmp file\n",
    "    fd, path = tempfile.mkstemp()\n",
    "    try:\n",
    "        with open(path, 'wb') as pointer:\n",
    "            pickle.dump(data, pointer)\n",
    "        with open(path, \"rb\") as pointer:\n",
    "            s3.upload_fileobj(pointer, bucket_name, key)\n",
    "    finally:\n",
    "        os.remove(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory:  /home/ec2-user/SageMaker/topic_modelling/NTM/tam_data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "def check_create_dir(dir):\n",
    "    if os.path.exists(dir):  # cleanup existing data folder\n",
    "        shutil.rmtree(dir)\n",
    "    os.mkdir(dir)\n",
    "    \n",
    "    \n",
    "data_dir = f'{base_dir}/Data'\n",
    "current_dir = os.getcwd()\n",
    "print(\"Current directory: \", current_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_pickle(f'{data_dir}/topic_modeling_data.pkl')\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.sample(frac=0.9, random_state=seed_value)\n",
    "test = data.loc[~data.index.isin(train.index)]\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_pickle(f'{data_dir}/topic_modeling_data_test.pkl')\n",
    "train.to_pickle(f'{data_dir}/topic_modeling_data_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_pickle(f'{data_dir}/topic_modeling_data_test.pkl')\n",
    "train = pd.read_pickle(f'{data_dir}/topic_modeling_data_train.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc_list = list(train['4_stop_words_removed'].values)\n",
    "test_doc_list = list(test['4_stop_words_removed'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 10889, list, 1210)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_doc_list), len(train_doc_list), type(test_doc_list), len(test_doc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('stack arn aws cloudformation region wa trying update launch configuration created stack use volume ami amazon linux stack update failed error invalid valid volume type standard try launch instance using ami via ec2 console able missing',\n",
       " 'hope great instance configured aws cli written script download file bucket run script manually terminal work working crontab')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_doc_list[1], test_doc_list[1], "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatizing and counting, this may take a few minutes...\n",
      "vocab size: 10355\n",
      "Done. Time elapsed: 0.52s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "print(\"Lemmatizing and counting, this may take a few minutes...\")\n",
    "start_time = time.time()\n",
    "vectorizer = CountVectorizer(\n",
    "    input=\"content\",\n",
    "    analyzer=\"word\",\n",
    "    stop_words=\"english\",\n",
    ")\n",
    "\n",
    "train_vectors = vectorizer.fit_transform(train_doc_list)\n",
    "test_vectors = vectorizer.transform(test_doc_list)\n",
    "\n",
    "vocab_list = vectorizer.get_feature_names()\n",
    "vocab_size = len(vocab_list)\n",
    "print(\"vocab size:\", vocab_size)\n",
    "print(\"Done. Time elapsed: {:.2f}s\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'> float32\n",
      "<class 'scipy.sparse.csr.csr_matrix'> float32\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse as sparse\n",
    "\n",
    "\n",
    "def setting_sparse_dtypes(vectors):\n",
    "    vectors = sparse.csr_matrix(vectors, dtype=np.float32)\n",
    "    print(type(vectors), vectors.dtype)\n",
    "    return vectors\n",
    "\n",
    "\n",
    "train_vectors_sparse = setting_sparse_dtypes(train_vectors)\n",
    "test_vectors_sparse = setting_sparse_dtypes(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_convert(sparray, prefix, fname_template=\"data_part{}.pbr\", n_parts=2):\n",
    "    import io\n",
    "    import sagemaker.amazon.common as smac\n",
    "\n",
    "    chunk_size = sparray.shape[0] // n_parts\n",
    "    for i in range(n_parts):\n",
    "\n",
    "        # Calculate start and end indices\n",
    "        start = i * chunk_size\n",
    "        end = (i + 1) * chunk_size\n",
    "        if i + 1 == n_parts:\n",
    "            end = sparray.shape[0]\n",
    "\n",
    "        # Convert to record protobuf\n",
    "        buf = io.BytesIO()\n",
    "        smac.write_spmatrix_to_sparse_tensor(array=sparray[start:end], file=buf, labels=None)\n",
    "        buf.seek(0)\n",
    "\n",
    "        fname = os.path.join(prefix, fname_template.format(i))\n",
    "        with open(fname, \"wb\") as f:\n",
    "            f.write(buf.getvalue())\n",
    "        print(\"Saved data to {}\".format(fname))\n",
    "\n",
    "\n",
    "train_data_dir = os.path.join(data_dir, \"train\")\n",
    "test_data_dir = os.path.join(data_dir, \"test\")\n",
    "\n",
    "check_create_dir(train_data_dir)\n",
    "check_create_dir(test_data_dir)\n",
    "\n",
    "split_convert(train_vectors_sparse, prefix=train_data_dir, fname_template=\"train_part{}.pbr\", n_parts=4)\n",
    "split_convert(test_vectors_sparse, prefix=test_data_dir, fname_template=\"test_part{}.pbr\", n_parts=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the vocabulary file\n",
    "To make use of the auxiliary channel for vocabulary file, we first save the text file with the name `vocab.txt` in the auxiliary directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_data_dir = os.path.join(data_dir, \"auxiliary\")\n",
    "check_create_dir(aux_data_dir)\n",
    "with open(os.path.join(aux_data_dir, \"vocab.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    for item in vocab_list:\n",
    "        f.write(item + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store Data on S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set location s3://bucket-sushant/topic_modelling/ntm/train\n",
      "Auxiliary data location s3://bucket-sushant/topic_modelling/ntm/auxiliary\n",
      "Test data location s3://bucket-sushant/topic_modelling/ntm/test\n",
      "Trained model will be saved at s3://bucket-sushant/topic_modelling/ntm/output\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "bucket = 'bucket-sushant'  # <or insert your own bucket name>#\n",
    "prefix = \"topic_modelling/ntm/\"\n",
    "\n",
    "train_prefix = os.path.join(prefix, \"train\")\n",
    "aux_prefix = os.path.join(prefix, \"auxiliary\")\n",
    "test_prefix = os.path.join(prefix, \"test\")\n",
    "output_prefix = os.path.join(prefix, \"output\")\n",
    "\n",
    "s3_train_data = os.path.join(\"s3://\", bucket, train_prefix)\n",
    "s3_aux_data = os.path.join(\"s3://\", bucket, aux_prefix)\n",
    "s3_test_data = os.path.join(\"s3://\", bucket, test_prefix)\n",
    "output_path = os.path.join(\"s3://\", bucket, output_prefix)\n",
    "print(\"Training set location\", s3_train_data)\n",
    "print(\"Auxiliary data location\", s3_aux_data)\n",
    "print(\"Test data location\", s3_test_data)\n",
    "print(\"Trained model will be saved at\", output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload the input directories to s3\n",
    "We use the `aws` command line interface (CLI) to upload the various input channels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "cmd_train = \"aws s3 cp \" + train_data_dir + \" \" + s3_train_data + \" --recursive\"\n",
    "p = subprocess.Popen(cmd_train, shell=True, stdout=subprocess.PIPE)\n",
    "p.communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd_test = \"aws s3 cp \" + test_data_dir + \" \" + s3_test_data + \" --recursive\"\n",
    "p = subprocess.Popen(cmd_test, shell=True, stdout=subprocess.PIPE)\n",
    "p.communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd_aux = \"aws s3 cp \" + aux_data_dir + \" \" + s3_aux_data + \" --recursive\"\n",
    "p = subprocess.Popen(cmd_aux, shell=True, stdout=subprocess.PIPE)\n",
    "p.communicate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The method get_image_uri has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: 1.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "import sagemaker\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "container = get_image_uri(boto3.Session().region_name, \"ntm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ntm = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type=\"ml.c4.xlarge\",\n",
    "    output_path=output_path,\n",
    "    sagemaker_session=sess,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 15\n",
    "ntm.set_hyperparameters(\n",
    "    num_topics=num_topics, feature_dim=vocab_size, mini_batch_size=60, epochs=50, sub_sample=0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.session import s3_input\n",
    "\n",
    "s3_train = s3_input(\n",
    "    s3_train_data, distribution=\"ShardedByS3Key\", content_type=\"application/x-recordio-protobuf\"\n",
    ")\n",
    "s3_test = s3_input(\n",
    "    s3_test_data, distribution=\"FullyReplicated\", content_type=\"application/x-recordio-protobuf\"\n",
    ")\n",
    "\n",
    "s3_aux = s3_input(s3_aux_data, distribution=\"FullyReplicated\", content_type=\"text/plain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ntm.fit({\"train\": s3_train, \"auxiliary\": s3_aux, \"test\": s3_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training job name: {}\".format(ntm.latest_training_job.job_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntm_predictor = ntm.deploy(initial_instance_count=1, instance_type=\"ml.m4.xlarge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "\n",
    "ntm_predictor.serializer = CSVSerializer()\n",
    "ntm_predictor.deserializer = JSONDeserializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_vectors = vectorizer.transform(test_doc_list).toarray()\n",
    "\n",
    "\n",
    "type(inference_vectors), inference_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = ntm_predictor.predict(inference_vectors[:10], initial_args={\"ContentType\": \"text/csv\"})\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batches(data, rows=10):\n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    predictions = []\n",
    "    for array in split_array:\n",
    "        results = ntm_predictor.predict(array, initial_args={\"ContentType\": \"text/csv\"})\n",
    "        predictions += [r[\"topic_weights\"] for r in results[\"predictions\"]]\n",
    "    return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = predict_batches(inference_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = {\n",
    "    0: \"reconnecting initiating connect sip subham chat update chime shilpa useable mouse apeksha christophe chirs imthian cloudwath neshon prompted chrish particularly\".split(),\n",
    "    1: \"timestamp password login showing unable launch window type shammi created tried server getting rdp panchal launched launching capacity role access\".split(),\n",
    "    2: \"initiating reconnecting reinitiating lost disconnected connect chat looping inititaing join dueto narrowing phone arajun vnet hardik vaishnavi fialed srishti bernardo\".split(),\n",
    "    3: \"phone amazon initiating machince inititaing fluctuation balraj thrugh shashank looping tsill shinde urgenty waited renitiating ghole scheuled monetization loo bos\".split(),\n",
    "    4: \"reconnecting reinitiating disconnected lost connect pfa resent bindushree mailing imthiyaaz imparied mate allen balaji hibernated cake saneesh conferencing manar monetization\".split(),\n",
    "    5: \"filename sudo module apt init yum rpm mnt nitro ascii ena line detached contain repository systemctl directory content nvme mount\".split(),\n",
    "    6: \"training toll international incoming respond documentation managed accept management follow pin sent cost return corner enquiry star center rated simultaneously\".split(),\n",
    "    7: \"reconnecting disconnected chat initiating connect update reconnect reponse nexus umair elk subhankar sublimits got domian loo kenedy mubulay neelansh unidentified\".split(),\n",
    "    8: \"underlying hardware inconvenience iop healthy burst failure graph health spike occur credit passing balance apologize experienced performance throughput cpuutilization metric\".split(),\n",
    "    9: \"reconnecting initiating connect chat disconnected lost subham connection struck anybody vinod retrying monthend postpone comminucation effecting pandey cofirm scheuled aravind\".split(),\n",
    "    10: \"helped click yes resolve let know issue heard continued wish mark close hour regarding open action want time note url\".split(),\n",
    "    11: \"reachability failed status check reconnecting failing joshi passed dear himanshu initiating disconnected rdp asap showing chat reachable got health failure\".split(),\n",
    "    12: \"initiating connect chat disconnected reconnecting verma janak inititaing tsill tring phone ssh update rayrao struck join suddnely looping fluctuation prodind\".split(),\n",
    "    13: \"chat disconnected initiating connect chime connecting join ssh urgent connection equipment resilient troubleshoot lost log host network mbaosxy commercially session\".split(),\n",
    "    14: \"resolved assistance contact ha heard continued wish case mark close regarding need hour action open web required note url want\".split(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_doc_list[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(results, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntm_predictor.delete_model()\n",
    "ntm_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference using S3 stored model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('arn:aws:iam::874163252636:role/service-role/AmazonSageMaker-ExecutionRole-20201201T202376',\n",
       " <sagemaker.session.Session at 0x7f54e2078978>,\n",
       " '382416733822.dkr.ecr.us-east-1.amazonaws.com/ntm:1')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "role, sess, container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model import Model\n",
    "from sagemaker.predictor import Predictor\n",
    "\n",
    "ntm_model = Model(\n",
    "    image_uri=container, \n",
    "    model_data=\"s3://bucket-sushant/topic_modelling/ntm/output/ntm-2021-09-01-16-29-04-809/output/model.tar.gz\", \n",
    "    role=role,\n",
    "    predictor_cls=Predictor,\n",
    "    sagemaker_session=sess,\n",
    "    name='01-NTM'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "ntm_predictor = ntm_model.deploy(initial_instance_count=1, instance_type=\"ml.m4.xlarge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sagemaker.predictor.Predictor at 0x7f54df120320>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ntm_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sagemaker.predictor.Predictor"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ntm_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "\n",
    "ntm_predictor.serializer = CSVSerializer()\n",
    "ntm_predictor.deserializer = JSONDeserializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (1210, 10355))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_vectors = vectorizer.transform(test_doc_list).toarray()\n",
    "type(inference_vectors), inference_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batches(data, rows=10):\n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    predictions = []\n",
    "    for array in split_array:\n",
    "        results = ntm_predictor.predict(array, initial_args={\"ContentType\": \"text/csv\"})\n",
    "        predictions += [r[\"topic_weights\"] for r in results[\"predictions\"]]\n",
    "    return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': [{'topic_weights': [0.0508086979, 0.0571757555, 0.0497882068, 0.0476639606, 0.0494563468, 0.0513480119, 0.0459508561, 0.0514453873, 0.0502470955, 0.0506516621, 0.3130582571, 0.0478635244, 0.0512152128, 0.053954497, 0.0293724649]}, {'topic_weights': [0.0229765028, 0.0613116771, 0.0217093546, 0.0203811899, 0.0221266989, 0.5712631941, 0.1023188531, 0.0221275054, 0.0296478104, 0.0232598335, 0.017914284, 0.0204995833, 0.0236266125, 0.0252140276, 0.0156228626]}, {'topic_weights': [0.0368073247, 0.0264481902, 0.039422892, 0.0222580899, 0.0365636237, 0.0398879126, 0.122978501, 0.0389436148, 0.0406348184, 0.0390544683, 0.1432041377, 0.0350537673, 0.0420784578, 0.0417799428, 0.2948842347]}, {'topic_weights': [0.0348242261, 0.0275568552, 0.0307695512, 0.0225278474, 0.0342815742, 0.1440174431, 0.3426134288, 0.031165652, 0.1460194439, 0.0343183093, 0.0248820912, 0.0330546945, 0.0338792093, 0.0397889614, 0.0203007311]}, {'topic_weights': [0.0368073247, 0.0264481902, 0.039422892, 0.0222580899, 0.0365636237, 0.0398879126, 0.122978501, 0.0389436148, 0.0406348184, 0.0390544683, 0.1432041377, 0.0350537673, 0.0420784578, 0.0417799428, 0.2948842347]}, {'topic_weights': [0.0359417647, 0.1079870686, 0.0346294492, 0.0315501392, 0.0360423177, 0.0450210981, 0.2947483659, 0.0344779231, 0.1671190858, 0.0359150358, 0.0288827643, 0.0332168676, 0.0355745703, 0.0465636216, 0.0323299393]}, {'topic_weights': [0.0368073247, 0.0264481902, 0.039422892, 0.0222580899, 0.0365636237, 0.0398879126, 0.122978501, 0.0389436148, 0.0406348184, 0.0390544683, 0.1432041377, 0.0350537673, 0.0420784578, 0.0417799428, 0.2948842347]}, {'topic_weights': [0.0341655314, 0.1088993251, 0.0341444798, 0.0341369696, 0.033371415, 0.0351364203, 0.0623177923, 0.0317158885, 0.4243397713, 0.0336801708, 0.0313088559, 0.0262347739, 0.0328438506, 0.042424798, 0.0352798402]}, {'topic_weights': [0.0508086979, 0.0571757555, 0.0497882068, 0.0476639606, 0.0494563468, 0.0513480119, 0.0459508561, 0.0514453873, 0.0502470955, 0.0506516621, 0.3130582571, 0.0478635244, 0.0512152128, 0.053954497, 0.0293724649]}, {'topic_weights': [0.0508086979, 0.0571757555, 0.0497882068, 0.0476639606, 0.0494563468, 0.0513480119, 0.0459508561, 0.0514453873, 0.0502470955, 0.0506516621, 0.3130582571, 0.0478635244, 0.0512152128, 0.053954497, 0.0293724649]}]}\n"
     ]
    }
   ],
   "source": [
    "results = ntm_predictor.predict(inference_vectors[:10], initial_args={\"ContentType\": \"text/csv\"})\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_results = predict_batches(inference_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0508087 , 0.05717576, 0.04978821, ..., 0.05121521, 0.0539545 ,\n",
       "        0.02937246],\n",
       "       [0.0229765 , 0.06131168, 0.02170935, ..., 0.02362661, 0.02521403,\n",
       "        0.01562286],\n",
       "       [0.03680732, 0.02644819, 0.03942289, ..., 0.04207846, 0.04177994,\n",
       "        0.29488423],\n",
       "       ...,\n",
       "       [0.0410105 , 0.18014887, 0.03824858, ..., 0.04187911, 0.05683108,\n",
       "        0.05252954],\n",
       "       [0.04833374, 0.11762124, 0.04327942, ..., 0.04722911, 0.05552241,\n",
       "        0.02699875],\n",
       "       [0.06866349, 0.10166455, 0.06707709, ..., 0.06681987, 0.06991782,\n",
       "        0.0562783 ]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1210, 15) (1210,)\n"
     ]
    }
   ],
   "source": [
    "arg_max_results = np.argmax(batch_results, axis=1)\n",
    "print(batch_results.shape, arg_max_results.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>customer_name</th>\n",
       "      <th>service</th>\n",
       "      <th>case_billing_region</th>\n",
       "      <th>customer_billing_country_name</th>\n",
       "      <th>comm_owner_agent_login</th>\n",
       "      <th>comm_body</th>\n",
       "      <th>case_creation_cal_date</th>\n",
       "      <th>comm_date_utc</th>\n",
       "      <th>comm_subject</th>\n",
       "      <th>case_severity</th>\n",
       "      <th>urls</th>\n",
       "      <th>4_stop_words_removed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7621010241</td>\n",
       "      <td>Mylan</td>\n",
       "      <td>Elastic Compute Cloud (EC2 - Windows)</td>\n",
       "      <td>APAC</td>\n",
       "      <td>INDIA</td>\n",
       "      <td>arizona</td>\n",
       "      <td>Please let us know if we helped resolve your i...</td>\n",
       "      <td>11/16/2020 0:00</td>\n",
       "      <td>11/17/2020 0:00</td>\n",
       "      <td>ASG Failed - IP limit</td>\n",
       "      <td>4</td>\n",
       "      <td>https://console.aws.amazon.com/support/feedbac...</td>\n",
       "      <td>please let know helped resolve issue yes click...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>7414621131</td>\n",
       "      <td>Tata Communications Ltd.</td>\n",
       "      <td>Elastic Compute Cloud (EC2 - Linux)</td>\n",
       "      <td>APAC</td>\n",
       "      <td>INDIA</td>\n",
       "      <td>tchemvur</td>\n",
       "      <td>Hi,  Hope you are doing great. Instance ID: i-...</td>\n",
       "      <td>9/23/2020 0:00</td>\n",
       "      <td>9/23/2020 0:00</td>\n",
       "      <td>AWS CLI not working from Crontab</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>hope great instance configured aws cli written...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>7682250211</td>\n",
       "      <td>Hotstar (Star TV India)</td>\n",
       "      <td>Elastic Compute Cloud (EC2 - Linux)</td>\n",
       "      <td>APAC</td>\n",
       "      <td>INDIA</td>\n",
       "      <td>arizona</td>\n",
       "      <td>Hello,  We haven't heard back from you regardi...</td>\n",
       "      <td>12/2/2020 0:00</td>\n",
       "      <td>12/9/2020 0:00</td>\n",
       "      <td>About Amazon Corretto a OpenJDK distribution.</td>\n",
       "      <td>4</td>\n",
       "      <td>https://console.aws.amazon.com/support/home?#/...</td>\n",
       "      <td>hello heard back regarding case continued supp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>8302246421</td>\n",
       "      <td>ALL_DEPRECATED</td>\n",
       "      <td>Elastic Compute Cloud (EC2 - Linux)</td>\n",
       "      <td>APAC</td>\n",
       "      <td>INDIA</td>\n",
       "      <td>anearin</td>\n",
       "      <td>Luke -  Thank you for taking a few minutes to ...</td>\n",
       "      <td>5/5/2021 0:00</td>\n",
       "      <td>5/18/2021 0:00</td>\n",
       "      <td>Additional Elastic IP Blocks for us-east-1, us...</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>luke thank taking minute chat today discussed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>8302246421</td>\n",
       "      <td>ALL_DEPRECATED</td>\n",
       "      <td>Elastic Compute Cloud (EC2 - Linux)</td>\n",
       "      <td>APAC</td>\n",
       "      <td>INDIA</td>\n",
       "      <td>arizona</td>\n",
       "      <td>Hello,  We haven't heard back from you regardi...</td>\n",
       "      <td>5/5/2021 0:00</td>\n",
       "      <td>5/13/2021 0:00</td>\n",
       "      <td>Additional Elastic IP Blocks for us-east-1, us...</td>\n",
       "      <td>4</td>\n",
       "      <td>https://console.aws.amazon.com/support/home?#/...</td>\n",
       "      <td>hello heard back regarding case continued supp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       case_id             customer_name  \\\n",
       "29  7621010241                     Mylan   \n",
       "35  7414621131  Tata Communications Ltd.   \n",
       "41  7682250211   Hotstar (Star TV India)   \n",
       "44  8302246421            ALL_DEPRECATED   \n",
       "46  8302246421            ALL_DEPRECATED   \n",
       "\n",
       "                                  service case_billing_region  \\\n",
       "29  Elastic Compute Cloud (EC2 - Windows)                APAC   \n",
       "35    Elastic Compute Cloud (EC2 - Linux)                APAC   \n",
       "41    Elastic Compute Cloud (EC2 - Linux)                APAC   \n",
       "44    Elastic Compute Cloud (EC2 - Linux)                APAC   \n",
       "46    Elastic Compute Cloud (EC2 - Linux)                APAC   \n",
       "\n",
       "   customer_billing_country_name comm_owner_agent_login  \\\n",
       "29                         INDIA                arizona   \n",
       "35                         INDIA               tchemvur   \n",
       "41                         INDIA                arizona   \n",
       "44                         INDIA                anearin   \n",
       "46                         INDIA                arizona   \n",
       "\n",
       "                                            comm_body case_creation_cal_date  \\\n",
       "29  Please let us know if we helped resolve your i...        11/16/2020 0:00   \n",
       "35  Hi,  Hope you are doing great. Instance ID: i-...         9/23/2020 0:00   \n",
       "41  Hello,  We haven't heard back from you regardi...         12/2/2020 0:00   \n",
       "44  Luke -  Thank you for taking a few minutes to ...          5/5/2021 0:00   \n",
       "46  Hello,  We haven't heard back from you regardi...          5/5/2021 0:00   \n",
       "\n",
       "      comm_date_utc                                       comm_subject  \\\n",
       "29  11/17/2020 0:00                              ASG Failed - IP limit   \n",
       "35   9/23/2020 0:00                   AWS CLI not working from Crontab   \n",
       "41   12/9/2020 0:00      About Amazon Corretto a OpenJDK distribution.   \n",
       "44   5/18/2021 0:00  Additional Elastic IP Blocks for us-east-1, us...   \n",
       "46   5/13/2021 0:00  Additional Elastic IP Blocks for us-east-1, us...   \n",
       "\n",
       "    case_severity                                               urls  \\\n",
       "29              4  https://console.aws.amazon.com/support/feedbac...   \n",
       "35              2                                               None   \n",
       "41              4  https://console.aws.amazon.com/support/home?#/...   \n",
       "44              4                                               None   \n",
       "46              4  https://console.aws.amazon.com/support/home?#/...   \n",
       "\n",
       "                                 4_stop_words_removed  \n",
       "29  please let know helped resolve issue yes click...  \n",
       "35  hope great instance configured aws cli written...  \n",
       "41  hello heard back regarding case continued supp...  \n",
       "44  luke thank taking minute chat today discussed ...  \n",
       "46  hello heard back regarding case continued supp...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['predicted_topic_pos'] = arg_max_results\n",
    "test['predicted_topics'] = test.predicted_topic_pos.apply(lambda x: topics[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['predicted_topic_pos'] = arg_max_results\n",
    "test['predicted_topics'] = test.predicted_topic_pos.apply(lambda x: topics[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>customer_name</th>\n",
       "      <th>service</th>\n",
       "      <th>case_billing_region</th>\n",
       "      <th>customer_billing_country_name</th>\n",
       "      <th>comm_owner_agent_login</th>\n",
       "      <th>comm_body</th>\n",
       "      <th>case_creation_cal_date</th>\n",
       "      <th>comm_date_utc</th>\n",
       "      <th>comm_subject</th>\n",
       "      <th>case_severity</th>\n",
       "      <th>urls</th>\n",
       "      <th>4_stop_words_removed</th>\n",
       "      <th>predicted_topic_pos</th>\n",
       "      <th>predicted_topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7621010241</td>\n",
       "      <td>Mylan</td>\n",
       "      <td>Elastic Compute Cloud (EC2 - Windows)</td>\n",
       "      <td>APAC</td>\n",
       "      <td>INDIA</td>\n",
       "      <td>arizona</td>\n",
       "      <td>Please let us know if we helped resolve your i...</td>\n",
       "      <td>11/16/2020 0:00</td>\n",
       "      <td>11/17/2020 0:00</td>\n",
       "      <td>ASG Failed - IP limit</td>\n",
       "      <td>4</td>\n",
       "      <td>https://console.aws.amazon.com/support/feedbac...</td>\n",
       "      <td>please let know helped resolve issue yes click...</td>\n",
       "      <td>10</td>\n",
       "      <td>[helped, click, yes, resolve, let, know, issue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>7414621131</td>\n",
       "      <td>Tata Communications Ltd.</td>\n",
       "      <td>Elastic Compute Cloud (EC2 - Linux)</td>\n",
       "      <td>APAC</td>\n",
       "      <td>INDIA</td>\n",
       "      <td>tchemvur</td>\n",
       "      <td>Hi,  Hope you are doing great. Instance ID: i-...</td>\n",
       "      <td>9/23/2020 0:00</td>\n",
       "      <td>9/23/2020 0:00</td>\n",
       "      <td>AWS CLI not working from Crontab</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>hope great instance configured aws cli written...</td>\n",
       "      <td>5</td>\n",
       "      <td>[filename, sudo, module, apt, init, yum, rpm, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>7682250211</td>\n",
       "      <td>Hotstar (Star TV India)</td>\n",
       "      <td>Elastic Compute Cloud (EC2 - Linux)</td>\n",
       "      <td>APAC</td>\n",
       "      <td>INDIA</td>\n",
       "      <td>arizona</td>\n",
       "      <td>Hello,  We haven't heard back from you regardi...</td>\n",
       "      <td>12/2/2020 0:00</td>\n",
       "      <td>12/9/2020 0:00</td>\n",
       "      <td>About Amazon Corretto a OpenJDK distribution.</td>\n",
       "      <td>4</td>\n",
       "      <td>https://console.aws.amazon.com/support/home?#/...</td>\n",
       "      <td>hello heard back regarding case continued supp...</td>\n",
       "      <td>14</td>\n",
       "      <td>[resolved, assistance, contact, ha, heard, con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>8302246421</td>\n",
       "      <td>ALL_DEPRECATED</td>\n",
       "      <td>Elastic Compute Cloud (EC2 - Linux)</td>\n",
       "      <td>APAC</td>\n",
       "      <td>INDIA</td>\n",
       "      <td>anearin</td>\n",
       "      <td>Luke -  Thank you for taking a few minutes to ...</td>\n",
       "      <td>5/5/2021 0:00</td>\n",
       "      <td>5/18/2021 0:00</td>\n",
       "      <td>Additional Elastic IP Blocks for us-east-1, us...</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>luke thank taking minute chat today discussed ...</td>\n",
       "      <td>6</td>\n",
       "      <td>[training, toll, international, incoming, resp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>8302246421</td>\n",
       "      <td>ALL_DEPRECATED</td>\n",
       "      <td>Elastic Compute Cloud (EC2 - Linux)</td>\n",
       "      <td>APAC</td>\n",
       "      <td>INDIA</td>\n",
       "      <td>arizona</td>\n",
       "      <td>Hello,  We haven't heard back from you regardi...</td>\n",
       "      <td>5/5/2021 0:00</td>\n",
       "      <td>5/13/2021 0:00</td>\n",
       "      <td>Additional Elastic IP Blocks for us-east-1, us...</td>\n",
       "      <td>4</td>\n",
       "      <td>https://console.aws.amazon.com/support/home?#/...</td>\n",
       "      <td>hello heard back regarding case continued supp...</td>\n",
       "      <td>14</td>\n",
       "      <td>[resolved, assistance, contact, ha, heard, con...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       case_id             customer_name  \\\n",
       "29  7621010241                     Mylan   \n",
       "35  7414621131  Tata Communications Ltd.   \n",
       "41  7682250211   Hotstar (Star TV India)   \n",
       "44  8302246421            ALL_DEPRECATED   \n",
       "46  8302246421            ALL_DEPRECATED   \n",
       "\n",
       "                                  service case_billing_region  \\\n",
       "29  Elastic Compute Cloud (EC2 - Windows)                APAC   \n",
       "35    Elastic Compute Cloud (EC2 - Linux)                APAC   \n",
       "41    Elastic Compute Cloud (EC2 - Linux)                APAC   \n",
       "44    Elastic Compute Cloud (EC2 - Linux)                APAC   \n",
       "46    Elastic Compute Cloud (EC2 - Linux)                APAC   \n",
       "\n",
       "   customer_billing_country_name comm_owner_agent_login  \\\n",
       "29                         INDIA                arizona   \n",
       "35                         INDIA               tchemvur   \n",
       "41                         INDIA                arizona   \n",
       "44                         INDIA                anearin   \n",
       "46                         INDIA                arizona   \n",
       "\n",
       "                                            comm_body case_creation_cal_date  \\\n",
       "29  Please let us know if we helped resolve your i...        11/16/2020 0:00   \n",
       "35  Hi,  Hope you are doing great. Instance ID: i-...         9/23/2020 0:00   \n",
       "41  Hello,  We haven't heard back from you regardi...         12/2/2020 0:00   \n",
       "44  Luke -  Thank you for taking a few minutes to ...          5/5/2021 0:00   \n",
       "46  Hello,  We haven't heard back from you regardi...          5/5/2021 0:00   \n",
       "\n",
       "      comm_date_utc                                       comm_subject  \\\n",
       "29  11/17/2020 0:00                              ASG Failed - IP limit   \n",
       "35   9/23/2020 0:00                   AWS CLI not working from Crontab   \n",
       "41   12/9/2020 0:00      About Amazon Corretto a OpenJDK distribution.   \n",
       "44   5/18/2021 0:00  Additional Elastic IP Blocks for us-east-1, us...   \n",
       "46   5/13/2021 0:00  Additional Elastic IP Blocks for us-east-1, us...   \n",
       "\n",
       "    case_severity                                               urls  \\\n",
       "29              4  https://console.aws.amazon.com/support/feedbac...   \n",
       "35              2                                               None   \n",
       "41              4  https://console.aws.amazon.com/support/home?#/...   \n",
       "44              4                                               None   \n",
       "46              4  https://console.aws.amazon.com/support/home?#/...   \n",
       "\n",
       "                                 4_stop_words_removed  predicted_topic_pos  \\\n",
       "29  please let know helped resolve issue yes click...                   10   \n",
       "35  hope great instance configured aws cli written...                    5   \n",
       "41  hello heard back regarding case continued supp...                   14   \n",
       "44  luke thank taking minute chat today discussed ...                    6   \n",
       "46  hello heard back regarding case continued supp...                   14   \n",
       "\n",
       "                                     predicted_topics  \n",
       "29  [helped, click, yes, resolve, let, know, issue...  \n",
       "35  [filename, sudo, module, apt, init, yum, rpm, ...  \n",
       "41  [resolved, assistance, contact, ha, heard, con...  \n",
       "44  [training, toll, international, incoming, resp...  \n",
       "46  [resolved, assistance, contact, ha, heard, con...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv(f'{data_dir}/test_predictions_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntm_predictor.delete_model()\n",
    "ntm_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "notice": "Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
